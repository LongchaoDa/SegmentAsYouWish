{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322d6430-8a42-47bb-8c7c-45d03697ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to install escnn first\n",
    "# !pip install escnn\n",
    "# !pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff89744b-ee9f-4bce-9a81-8da74f41ba94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Specify the GPU you want to use, for example, GPU 0\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "from typing import Tuple\n",
    "import escnn\n",
    "import torch\n",
    "import torchvision\n",
    "from rot_mnist import RotatedMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import kornia as K\n",
    "from equiv_networks import ESCNNEquivariantNetwork\n",
    "from canonicalization_discrete_group import DiscreteGroupImageCanonicalization\n",
    "from utils import train_classifer, eval_acc\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c174a9-2445-4415-99b4-7c298a923cbc",
   "metadata": {},
   "source": [
    "## 1. Create a CNN prediction network and train it on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a149b573-a827-4428-9e2f-6a9697199709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, hidden_dim, kernel_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(hidden_dim, hidden_dim, kernel_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(hidden_dim, out_channels, kernel_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # Apply average pooling over spatial dimensions.\n",
    "        return out.mean((2,3))\n",
    "\n",
    "prediction_network = CNN(in_channels = 1, out_channels = 10, kernel_size = 5, hidden_dim = 64).to(device)\n",
    "\n",
    "# Define transformations\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train_dataset, batch_size=512, shuffle=True)\n",
    "mnist_valid_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_valid_loader = torch.utils.data.DataLoader(dataset=mnist_valid_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(prediction_network.parameters(), 0.001) \n",
    "train_classifer(prediction_network, mnist_train_loader, mnist_valid_loader, num_epoch = 50, optimizer = optimizer)\n",
    "# torch.save(prediction_network, \"prediction_network.pth\")\n",
    "# prediction_network = torch.load(\"prediction_network.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2037bdb-8665-48c8-a117-0945ceb96d0d",
   "metadata": {},
   "source": [
    "## 2. Achieve Equivariance with Canonicalization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e592f-144d-4854-a6ea-e8d73392eb93",
   "metadata": {},
   "source": [
    "### 2.1 Canonicalization Network: $\\phi(x) = c(x)\\;f(c^{-1}(x)\\;x)$ where $f$ is the prediction network and $c$ is the equivariant network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876a5f9c-1a86-400e-8854-733c6fa38632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# design canonicalization hyperparams class\n",
    "class CanonicalizationHyperparams:\n",
    "    def __init__(self):\n",
    "        self.network_type = \"escnn\" # group equivariant canonicalization\n",
    "        self.resize_shape = 28 # resize shape for the canonicalization network\n",
    "        self.network_hyperparams = {\n",
    "            \"kernel_size\": 5, # Kernel size for the canonization network\n",
    "            \"hidden_dim\": 32,\n",
    "            \"out_channels\": 32, # Number of output channels for the canonization network\n",
    "            \"num_layers\": 5, # Number of layers in the canonization network\n",
    "            \"group_type\": \"roto-reflection\",#\"roto-reflection\", #rotation\", # Type of group for the canonization network\n",
    "            \"group_order\": 4, # Number of rotations for the canonization network \n",
    "            # \"num_rotations\": 4\n",
    "        }\n",
    "        self.beta = 1.0 \n",
    "        self.input_crop_ratio = 1.0\n",
    "        self.gradient_trick = \"gumbel_softmax\"#\"straight_through\"\n",
    "        \n",
    "canonicalization_hyperparams = CanonicalizationHyperparams()\n",
    "image_shape = (1, 28, 28)\n",
    "\n",
    "# Equivariant Network c(x)\n",
    "canonicalization_network = ESCNNEquivariantNetwork(inp_channels = image_shape[0], **canonicalization_hyperparams.network_hyperparams).to(device)\n",
    "canonicalizer = DiscreteGroupImageCanonicalization(canonicalization_network, canonicalization_hyperparams, image_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698838d-b326-4235-80f8-9967dd2eeb35",
   "metadata": {},
   "source": [
    "### 2.2 Train the canonicalization network on the ***rotation*** MNIST datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdcd9715-dbac-46fa-b889-9b742cc61bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies of the Prediction Network on the Original and Rotated MNIST Test Sets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.98873, 0.33418)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Rotation MNIST dataset\n",
    "rot_mnist_train_dataset = RotatedMNIST(root=\"./data\", partition=\"train\", augment=\"None\")\n",
    "rot_mnist_train_loader = torch.utils.data.DataLoader(rot_mnist_train_dataset, batch_size=512, shuffle=True, num_workers=4)\n",
    "rot_mnist_valid_dataset = RotatedMNIST(root=\"./data\", partition=\"valid\", augment=\"None\")\n",
    "rot_mnist_valid_loader = torch.utils.data.DataLoader(rot_mnist_valid_dataset, batch_size=512, shuffle=False, num_workers=4)\n",
    "\n",
    "# the prediction network perform poorly on the rotated mnist test set.\n",
    "print(\"Accuracies of the Prediction Network on the Original and Rotated MNIST Test Sets\")\n",
    "eval_acc(prediction_network, mnist_valid_loader), eval_acc(prediction_network, rot_mnist_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd6677-8a6c-4fcb-966d-6e602d2333af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Accuracy: 0.632 | Train Loss: 2.922 \n",
      "Epoch 11 | Train Accuracy: 0.870 | Train Loss: 1.488 \n",
      "Epoch 21 | Train Accuracy: 0.891 | Train Loss: 1.351 \n",
      "Epoch 31 | Train Accuracy: 0.898 | Train Loss: 1.292 \n",
      "Epoch 41 | Train Accuracy: 0.905 | Train Loss: 1.255 \n",
      "Epoch 51 | Train Accuracy: 0.907 | Train Loss: 1.238 \n",
      "Epoch 61 | Train Accuracy: 0.910 | Train Loss: 1.216 \n",
      "Epoch 81 | Train Accuracy: 0.913 | Train Loss: 1.201 \n",
      "Epoch 91 | Train Accuracy: 0.913 | Train Loss: 1.199 \n",
      "Accuracy of Prediction Network alone on Rotated Test Set: 0.7809\n",
      "Accuracy of Canonicalizer + Prediction Network on Rotated Test Set: 0.8131\n"
     ]
    }
   ],
   "source": [
    "# train canonicalization_network and prediction_network together 0.0001 0.01\n",
    "# the goal is to make the canonicalization network to produce canonical forms that align with the prediction network.\n",
    "\n",
    "canonicalization_network = ESCNNEquivariantNetwork(inp_channels = image_shape[0], **canonicalization_hyperparams.network_hyperparams).to(device)\n",
    "canonicalizer = DiscreteGroupImageCanonicalization(canonicalization_network, canonicalization_hyperparams, image_shape).to(device)\n",
    "can_optimizer = torch.optim.AdamW([\n",
    "        {'params': prediction_network.parameters(), 'lr': 1e-3},\n",
    "        {'params': canonicalizer.parameters(), 'lr': 1e-3},\n",
    "    ])\n",
    "\n",
    "best_valid_acc = 0\n",
    "loss_fun = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(can_optimizer, step_size=1, gamma=0.95)\n",
    "for epoch in range(100):\n",
    "    train_loss, train_acc, count = [], 0, 0\n",
    "    for x, y in rot_mnist_train_loader:\n",
    "        can_optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        canonicalized_x = canonicalizer(x)\n",
    "        pred = prediction_network(canonicalized_x)\n",
    "        loss = loss_fun(pred, y) \n",
    "        loss += canonicalizer.get_prior_regularization_loss()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc += (y == pred.argmax(dim=-1)).sum().cpu().data.numpy()\n",
    "        count += y.shape[0]\n",
    "        loss.backward()\n",
    "        can_optimizer.step()\n",
    "    \n",
    "    for x, y in mnist_train_loader:\n",
    "        can_optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        canonicalized_x = canonicalizer(x)\n",
    "        pred = prediction_network(canonicalized_x)\n",
    "        loss = loss_fun(pred, y) \n",
    "        loss += canonicalizer.get_prior_regularization_loss()\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc += (y == pred.argmax(dim=-1)).sum().cpu().data.numpy()\n",
    "        count += y.shape[0]\n",
    "        loss.backward()\n",
    "        can_optimizer.step()\n",
    "\n",
    "    train_acc = train_acc/count\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch {} | Train Accuracy: {:0.3f} | Train Loss: {:0.3f} \".format(epoch+1, train_acc, np.mean(train_loss)))\n",
    "        \n",
    "print(\"Accuracy of Prediction Network alone on Rotated Test Set: {}\".format(eval_acc(prediction_network, rot_mnist_valid_loader)))\n",
    "print(\"Accuracy of Canonicalizer + Prediction Network on Rotated Test Set: {}\".format(eval_acc(torch.nn.Sequential(canonicalizer, prediction_network), rot_mnist_valid_loader)))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb082de-5340-4615-905b-a3983e3fa0f8",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1d94d9-144d-4344-8dd5-41f99cd79136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x, test_y = next(iter(rot_mnist_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "942cad81-1e80-45c3-9ff4-e9cab6c82456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_x[idx, 0])\n",
    "plt.title(\"Rotated \" + str(test_y[idx].numpy()), size = 15)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(canonicalizer(test_x.to(device)).cpu().detach()[idx, 0])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Canonicalized \" + str(test_y[idx].numpy()), size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef97e0-ea20-408f-9779-3b2bb7f86347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
